{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RKHS Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junzhewu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/junzhewu/.local/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=False)\n",
      "  warnings.warn(\n",
      "/home/junzhewu/.local/lib/python3.9/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 161\u001b[0m\n\u001b[1;32m    148\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GSSTrainer(model\u001b[38;5;241m=\u001b[39mgaussModel, \n\u001b[1;32m    149\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    150\u001b[0m     train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     render_kwargs\u001b[38;5;241m=\u001b[39mrender_kwargs,\n\u001b[1;32m    158\u001b[0m )\n\u001b[1;32m    160\u001b[0m trainer\u001b[38;5;241m.\u001b[39mon_evaluate_step()\n\u001b[0;32m--> 161\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36mGSSTrainer.on_train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# ic(self.data['camera'][ind].unsqueeze(0).shape)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# ic(depth.shape)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# ic(alpha.shape)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# ic(rgb.shape)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m points \u001b[38;5;241m=\u001b[39m get_point_clouds_tiles(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m][ind]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), depth\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), alpha\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), rgb\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 77\u001b[0m rkhs_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrkhs_global_scale_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scaling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# total_loss = (1-self.lambda_dssim) * l1_loss + self.lambda_dssim * ssim_loss + depth_loss * self.lambda_depth\u001b[39;00m\n\u001b[1;32m     81\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m rkhs_loss[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m rkhs_loss[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mrkhs_loss[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/projects/torch-splatting/rkhs_splatting/utils/loss_utils.py:43\u001b[0m, in \u001b[0;36mrkhs_global_scale_loss\u001b[0;34m(prediction_tiles, gt_tiles, gt_rgb, scale3d, use_geometry, use_rgb)\u001b[0m\n\u001b[1;32m     40\u001b[0m scale2d_tiles \u001b[38;5;241m=\u001b[39m prediction_tiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale2d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     41\u001b[0m label_tiles \u001b[38;5;241m=\u001b[39m prediction_tiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 43\u001b[0m gt_mean2d_tiles \u001b[38;5;241m=\u001b[39m \u001b[43mgt_tiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean2d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m gt_mean3d_tiles \u001b[38;5;241m=\u001b[39m gt_tiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean3d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     45\u001b[0m gt_label_tiles \u001b[38;5;241m=\u001b[39m gt_tiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean2d'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import rkhs_splatting.utils as utils\n",
    "from rkhs_splatting.trainer import Trainer\n",
    "import rkhs_splatting.utils.loss_utils as loss_utils\n",
    "from rkhs_splatting.utils.data_utils import read_all\n",
    "from rkhs_splatting.utils.camera_utils import to_viewpoint_camera\n",
    "from rkhs_splatting.utils.point_utils import get_point_clouds, get_point_clouds_tiles\n",
    "from rkhs_splatting.gauss_model import RKHSModelGlobalScale\n",
    "from rkhs_splatting.gauss_render import RKHSRendererGlobalScale\n",
    "import datetime\n",
    "import pathlib\n",
    "from icecream import ic\n",
    "\n",
    "import contextlib\n",
    "\n",
    "from pytorch_memlab import LineProfiler\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "USE_GPU_PYTORCH = True\n",
    "USE_PROFILE = False\n",
    "\n",
    "class GSSTrainer(Trainer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = kwargs.get('data')\n",
    "        self.gaussRender = RKHSRendererGlobalScale(**kwargs.get('render_kwargs', {}))\n",
    "        self.lambda_dssim = 0.2\n",
    "        self.lambda_depth = 0.0\n",
    "        # create a file self.results_folder / f'eval.csv'\n",
    "        with open(self.results_folder / 'eval.csv', 'w') as f:\n",
    "            f.write('iter,loss,total,l1,ssim,depth,psnr\\n')\n",
    "        self.tensorboard_writer = SummaryWriter(log_dir=self.results_folder)\n",
    "\n",
    "\n",
    "    \n",
    "    def on_train_step(self):\n",
    "        # ind = np.random.choice(len(self.data['camera']))\n",
    "        ind = 0\n",
    "        camera = self.data['camera'][ind]\n",
    "        rgb = self.data['rgb'][ind]\n",
    "        depth = self.data['depth'][ind]\n",
    "        alpha = self.data['alpha'][ind]\n",
    "        mask = (self.data['alpha'][ind] > 0.5)\n",
    "        if USE_GPU_PYTORCH:\n",
    "            camera = to_viewpoint_camera(camera)\n",
    "\n",
    "        if USE_PROFILE:\n",
    "            prof = profile(activities=[ProfilerActivity.CUDA], with_stack=True)\n",
    "        else:\n",
    "            prof = contextlib.nullcontext()\n",
    "\n",
    "        with prof:\n",
    "            max_scaling = torch.scalar_tensor(0.025, device=\"cuda\")\n",
    "            if self.model.get_scaling > max_scaling:\n",
    "                self.model.set_scaling(max_scaling)\n",
    "            out = self.gaussRender(pc=self.model, camera=camera)\n",
    "\n",
    "        if USE_PROFILE:\n",
    "            print(prof.key_averages(group_by_stack_n=True).table(sort_by='self_cuda_time_total', row_limit=20))\n",
    "\n",
    "\n",
    "\n",
    "        l1_loss = loss_utils.l1_loss(out['render'], rgb)\n",
    "        depth_loss = loss_utils.l1_loss(out['depth'][..., 0][mask], depth[mask])\n",
    "        ssim_loss = 1.0-loss_utils.ssim(out['render'], rgb)\n",
    "\n",
    "        # ic(self.data['camera'][ind].unsqueeze(0).shape)\n",
    "        # ic(depth.shape)\n",
    "        # ic(alpha.shape)\n",
    "        # ic(rgb.shape)\n",
    "\n",
    "        points = get_point_clouds_tiles(self.data['camera'][ind].unsqueeze(0), depth.unsqueeze(0), alpha.unsqueeze(0), rgb.unsqueeze(0))\n",
    "\n",
    "\n",
    "        rkhs_loss = loss_utils.rkhs_global_scale_loss(out['tiles'], points, rgb, self.model.get_scaling)\n",
    "\n",
    "\n",
    "        # total_loss = (1-self.lambda_dssim) * l1_loss + self.lambda_dssim * ssim_loss + depth_loss * self.lambda_depth\n",
    "        total_loss = rkhs_loss[0] + rkhs_loss[1] - 2*rkhs_loss[2]\n",
    "        psnr = utils.img2psnr(out['render'], rgb)\n",
    "        log_dict = {'total': total_loss,'l1':l1_loss, 'ssim': ssim_loss, 'depth': depth_loss, 'psnr': psnr}\n",
    "\n",
    "        with open(self.results_folder / 'eval.csv', 'a') as f:\n",
    "            f.write(f'{self.step},{total_loss},{l1_loss},{ssim_loss},{depth_loss},{psnr}\\n')\n",
    "\n",
    "        self.tensorboard_writer.add_scalar('loss/total', total_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss0', rkhs_loss[0], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss1', rkhs_loss[1], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss2', rkhs_loss[2], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/l1', l1_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/ssim', ssim_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/depth', depth_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('params/scaling', self.model.get_scaling, self.step)\n",
    "        \n",
    "        self.tensorboard_writer.add_scalar('psnr', psnr, self.step)\n",
    "\n",
    "        return total_loss, log_dict\n",
    "\n",
    "    def on_evaluate_step(self, **kwargs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        ind = np.random.choice(len(self.data['camera']))\n",
    "        camera = self.data['camera'][ind]\n",
    "        if USE_GPU_PYTORCH:\n",
    "            camera = to_viewpoint_camera(camera)\n",
    "\n",
    "        rgb = self.data['rgb'][ind].detach().cpu().numpy()\n",
    "        out = self.gaussRender(pc=self.model, camera=camera)\n",
    "        rgb_pd = out['render'].detach().cpu().numpy()\n",
    "        depth_pd = out['depth'].detach().cpu().numpy()[..., 0]\n",
    "        depth = self.data['depth'][ind].detach().cpu().numpy()\n",
    "        depth = np.concatenate([depth, depth_pd], axis=1)\n",
    "        depth = (1 - depth / depth.max())\n",
    "        depth = plt.get_cmap('jet')(depth)[..., :3]\n",
    "        image = np.concatenate([rgb, rgb_pd], axis=1)\n",
    "        image = np.concatenate([image, depth], axis=0)\n",
    "        utils.imwrite(str(self.results_folder / f'image-{self.step}.png'), image)\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "folder = './data/B075X65R3X'\n",
    "data = read_all(folder, resize_factor=0.5)\n",
    "data = {k: v.to(device) for k, v in data.items()}\n",
    "data['depth_range'] = torch.Tensor([[1,3]]*len(data['rgb'])).to(device)\n",
    "\n",
    "# ic(data['camera'].shape)\n",
    "# ic(data['depth'].shape)\n",
    "# ic(data['alpha'].shape)\n",
    "# ic(data['rgb'].shape)\n",
    "\n",
    "\n",
    "points = get_point_clouds(data['camera'], data['depth'], data['alpha'], data['rgb'])\n",
    "raw_points = points.random_sample(2**14)\n",
    "# raw_points.write_ply(open('points.ply', 'wb'))\n",
    "\n",
    "gaussModel = RKHSModelGlobalScale(sh_degree=4, debug=False)\n",
    "gaussModel.create_from_pcd(pcd=raw_points)\n",
    "\n",
    "render_kwargs = {\n",
    "    'white_bkgd': True,\n",
    "}\n",
    "# folder_name = datetime.datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "folder_name = 'test'\n",
    "results_folder = pathlib.Path('result/'+folder_name)\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trainer = GSSTrainer(model=gaussModel, \n",
    "    data=data,\n",
    "    train_batch_size=1, \n",
    "    train_num_steps=25000,\n",
    "    i_image =100,\n",
    "    train_lr=1e-3, \n",
    "    amp=False,\n",
    "    fp16=False,\n",
    "    results_folder=results_folder,\n",
    "    render_kwargs=render_kwargs,\n",
    ")\n",
    "\n",
    "trainer.on_evaluate_step()\n",
    "trainer.on_train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_splatting.utils.camera_utils import parse_camera\n",
    "from icecream import ic\n",
    "from plotly_utils import *\n",
    "\n",
    "ind=0\n",
    "camera = trainer.data['camera'][ind].unsqueeze(0)\n",
    "rgb = trainer.data['rgb'][ind].unsqueeze(0)\n",
    "depth = trainer.data['depth'][ind].unsqueeze(0)\n",
    "alpha = trainer.data['alpha'][ind].unsqueeze(0)\n",
    "mask = (trainer.data['alpha'][ind] > 0.5).unsqueeze(0)\n",
    "Hs, Ws, intrinsics, c2ws = parse_camera(camera)\n",
    "W, H = int(Ws[0].item()), int(Hs[0].item())\n",
    "\n",
    "\n",
    "points = get_point_clouds_tiles(camera, depth, alpha, rgb)\n",
    "N = len(points)\n",
    "M = len(points[0])\n",
    "P = points[0][0].coords.shape[0]\n",
    "\n",
    "out = trainer.gaussRender(pc=trainer.model, camera=to_viewpoint_camera(trainer.data['camera'][ind]))\n",
    "# rkhs_loss = loss_utils.rkhs_global_scale_loss(out['tiles'], points, rgb, trainer.model.get_scaling)\n",
    "\n",
    "prediction_tiles = out['tiles']\n",
    "gt_points = points\n",
    "gt_rgb = rgb\n",
    "scale3d = trainer.model.get_scaling\n",
    "\n",
    "mean2d_tiles = prediction_tiles['mean2d']\n",
    "mean3d_tiles = prediction_tiles['mean3d']\n",
    "scale2d_tiles = prediction_tiles['scale2d']\n",
    "label_tiles = prediction_tiles['label']\n",
    "\n",
    "N = len(mean2d_tiles)\n",
    "M = len(mean2d_tiles[0])\n",
    "T = gt_rgb.shape[0]//N\n",
    "\n",
    "scale3d_squared = scale3d**2\n",
    "\n",
    "import numpy as np\n",
    "mean_tile_number = np.mean([scale2d_tiles[v][u].shape[0] for v in range(N) for u in range(M)])\n",
    "\n",
    "# local map norm, training image norm, inner product\n",
    "loss = [0, 0, 0]\n",
    "init = False\n",
    "# for v in range(N):\n",
    "#     for u in range(M):\n",
    "        \n",
    "#         B = mean2d_tiles[v][u].shape[0]\n",
    "#         if B == 0 and init:\n",
    "#             continue\n",
    "#         init = True\n",
    "#         print(v,u)\n",
    "\n",
    "#         pc_tile = gt_points[v][u]\n",
    "#         pc_tile = pc_tile.random_sample(300)\n",
    "#         gt_label_tile = torch.from_numpy(pc_tile.select_channels(['R', 'G', 'B'])).to(scale3d.device)\n",
    "#         gt_points_tile = torch.from_numpy(pc_tile.coords).to(scale3d.device)\n",
    "#         P = gt_label_tile.shape[0]\n",
    "\n",
    "#         # ic(M, N, B, P, T)\n",
    "\n",
    "#         gt_label_tile_unsq0 = gt_label_tile.unsqueeze(0)\n",
    "#         gt_label_tile_unsq1 = gt_label_tile.unsqueeze(1)\n",
    "#         gt_points_tile_unsq0 = gt_points_tile.unsqueeze(0)\n",
    "#         gt_points_tile_unsq1 = gt_points_tile.unsqueeze(1)\n",
    "\n",
    "#         label_tile = label_tiles[v][u][0][:300] # only rgb for now\n",
    "#         label_tile_unsq0 = label_tile.unsqueeze(0)\n",
    "#         label_tile_unsq1 = label_tile.unsqueeze(1)\n",
    "#         mean3d_tile = mean3d_tiles[v][u][:300]\n",
    "#         mean3d_tile_unsq0 = mean3d_tile.unsqueeze(0)\n",
    "#         mean3d_tile_unsq1 = mean3d_tile.unsqueeze(1)\n",
    "\n",
    "#         # inner product between local map and current frame\n",
    "#         label2 = (label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1)\n",
    "#         point2 = (-0.5 * (mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1) / scale3d_squared).exp()\n",
    "#         # point2 = (-0.5 * (mean3d_tile_unsq1 - gt_points_tile_unsq0).abs().pow(3).sum(-1).pow(2/3) / scale3d_squared).exp()\n",
    "#         loss2 = label2 * point2\n",
    "\n",
    "#         # local map inner product\n",
    "#         label0 = (label_tile_unsq1 - label_tile_unsq0).pow(2).sum(-1)\n",
    "#         point0 = (-0.5 * (mean3d_tile_unsq1 - mean3d_tile_unsq0).pow(2).sum(-1) / scale3d_squared).exp()\n",
    "#         loss0 = label0 * point0\n",
    "\n",
    "#         # current frame inner product\n",
    "#         label1 = (gt_label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1)\n",
    "#         point1 = (-0.5 * (gt_points_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1) / scale3d_squared).exp()\n",
    "#         loss1 = label1 * point1\n",
    "\n",
    "#         # ic(loss0.sum(), loss1.sum(), loss2.sum())\n",
    "\n",
    "#         loss[0] = loss0.sum() + loss[0]\n",
    "#         loss[1] = loss1.sum() + loss[1]\n",
    "#         loss[2] = loss2.sum() + loss[2]\n",
    "\n",
    "\n",
    "# ic(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=2\n",
    "u=2\n",
    "\n",
    "B = mean2d_tiles[v][u].shape[0]\n",
    "pc_tile = gt_points[v][u]\n",
    "# pc_tile = pc_tile.random_sample(300)\n",
    "gt_label_tile = torch.from_numpy(pc_tile.select_channels(['R', 'G', 'B'])/255.0).to(scale3d.device)\n",
    "gt_points_tile = torch.from_numpy(pc_tile.coords).to(scale3d.device)\n",
    "P = gt_label_tile.shape[0]\n",
    "\n",
    "\n",
    "gt_label_tile_unsq0 = gt_label_tile.unsqueeze(0)\n",
    "gt_label_tile_unsq1 = gt_label_tile.unsqueeze(1)\n",
    "gt_points_tile_unsq0 = gt_points_tile.unsqueeze(0)\n",
    "gt_points_tile_unsq1 = gt_points_tile.unsqueeze(1)\n",
    "\n",
    "label_tile = label_tiles[v][u][0] # only rgb for now\n",
    "label_tile_unsq0 = label_tile.unsqueeze(0)\n",
    "label_tile_unsq1 = label_tile.unsqueeze(1)\n",
    "mean3d_tile = mean3d_tiles[v][u]\n",
    "mean3d_tile_unsq0 = mean3d_tile.unsqueeze(0)\n",
    "mean3d_tile_unsq1 = mean3d_tile.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| M: 4, N: 4, B: 3013, P: 4096, T: 0\n",
      "ic| label_tile_unsq1.shape: torch.Size([3013, 1, 3])\n",
      "ic| gt_label_tile_unsq0.shape: torch.Size([1, 4096, 3])\n",
      "ic| (label_tile_unsq1 - gt_label_tile_unsq0).shape: torch.Size([3013, 4096, 3])\n",
      "ic| label_tile_unsq1[:3]: tensor([[[0.6902, 0.4627, 0.3529]],\n",
      "                          \n",
      "                                  [[0.7529, 0.5137, 0.4157]],\n",
      "                          \n",
      "                                  [[0.7333, 0.4941, 0.3765]]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "ic| gt_label_tile_unsq0[0, :3]: tensor([[0.7412, 0.4784, 0.3608],\n",
      "                                        [0.7020, 0.4431, 0.3255],\n",
      "                                        [0.6784, 0.4196, 0.3020]], device='cuda:0')\n",
      "ic| (label_tile_unsq1 - gt_label_tile_unsq0).shape: torch.Size([3013, 4096, 3])\n",
      "ic| (label_tile_unsq1 - gt_label_tile_unsq0)[:3, :3]: tensor([[[-0.0510, -0.0157, -0.0078],\n",
      "                                                               [-0.0118,  0.0196,  0.0275],\n",
      "                                                               [ 0.0118,  0.0431,  0.0510]],\n",
      "                                                      \n",
      "                                                              [[ 0.0118,  0.0353,  0.0549],\n",
      "                                                               [ 0.0510,  0.0706,  0.0902],\n",
      "                                                               [ 0.0745,  0.0941,  0.1137]],\n",
      "                                                      \n",
      "                                                              [[-0.0078,  0.0157,  0.0157],\n",
      "                                                               [ 0.0314,  0.0510,  0.0510],\n",
      "                                                               [ 0.0549,  0.0745,  0.0745]]], device='cuda:0',\n",
      "                                                             grad_fn=<SliceBackward0>)\n",
      "ic| (label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1).shape: torch.Size([3013, 4096])\n",
      "ic| (label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1)[:3, :3]: tensor([[0.0029, 0.0013, 0.0046],\n",
      "                                                                             [0.0044, 0.0157, 0.0273],\n",
      "                                                                             [0.0006, 0.0062, 0.0141]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0029, 0.0013, 0.0046],\n",
       "        [0.0044, 0.0157, 0.0273],\n",
       "        [0.0006, 0.0062, 0.0141]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(M, N, B, P, T)\n",
    "\n",
    "ic(label_tile_unsq1.shape)\n",
    "ic(gt_label_tile_unsq0.shape)\n",
    "ic((label_tile_unsq1 - gt_label_tile_unsq0).shape)\n",
    "\n",
    "# print first 3\n",
    "ic(label_tile_unsq1[:3])\n",
    "ic(gt_label_tile_unsq0[0, :3])\n",
    "ic((label_tile_unsq1 - gt_label_tile_unsq0).shape)\n",
    "ic((label_tile_unsq1 - gt_label_tile_unsq0)[:3, :3])\n",
    "ic((label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1).shape)\n",
    "ic((label_tile_unsq1 - gt_label_tile_unsq0).pow(2).sum(-1)[:3, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| mean3d_tile_unsq1[:3]: tensor([[[0.3049, 0.5026, 0.4256]],\n",
      "                           \n",
      "                                   [[0.2670, 0.4231, 0.4998]],\n",
      "                           \n",
      "                                   [[0.3084, 0.4932, 0.4271]]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "ic| gt_points_tile_unsq0[0, :3]: tensor([[0.2326, 0.3935, 0.5118],\n",
      "                                         [0.2278, 0.3926, 0.5082],\n",
      "                                         [0.2229, 0.3917, 0.5045]], device='cuda:0')\n",
      "ic| (mean3d_tile_unsq1 - gt_points_tile_unsq0).shape: torch.Size([3013, 4096, 3])\n",
      "ic| (mean3d_tile_unsq1 - gt_points_tile_unsq0)[:3,:3]: tensor([[[ 0.0723,  0.1090, -0.0863],\n",
      "                                                                [ 0.0771,  0.1100, -0.0826],\n",
      "                                                                [ 0.0820,  0.1109, -0.0789]],\n",
      "                                                       \n",
      "                                                               [[ 0.0344,  0.0295, -0.0120],\n",
      "                                                                [ 0.0392,  0.0305, -0.0084],\n",
      "                                                                [ 0.0441,  0.0314, -0.0047]],\n",
      "                                                       \n",
      "                                                               [[ 0.0758,  0.0996, -0.0848],\n",
      "                                                                [ 0.0807,  0.1006, -0.0811],\n",
      "                                                                [ 0.0855,  0.1015, -0.0775]]], device='cuda:0',\n",
      "                                                              grad_fn=<SliceBackward0>)\n",
      "ic| (mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1)[:3,:3]: tensor([[0.0246, 0.0249, 0.0253],\n",
      "                                                                              [0.0022, 0.0025, 0.0030],\n",
      "                                                                              [0.0229, 0.0232, 0.0236]],"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "ic| scale3d_squared: tensor(1.0000e-04, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "ic| (mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1) / scale3d_squared: tensor([[  245.5807,   248.6852,   252.5532,  ...,  6337.1797,  6453.3540,\n",
      "                                                                                           6728.5181],\n",
      "                                                                                         [   21.9938,    25.3738,    29.5216,  ...,  6931.5171,  7050.3867,\n",
      "                                                                                           7331.9058],\n",
      "                                                                                         [  228.6542,   232.0342,   236.1821,  ...,  6371.8721,  6488.8457,\n",
      "                                                                                           6764.6738],\n",
      "                                                                                         ...,\n",
      "                                                                                         [15080.5449, 14954.1230, 14828.4131,  ...,  5082.9565,  5067.2808,\n",
      "                                                                                           4968.5518],\n",
      "                                                                                         [15146.9541, 15018.6699, 14891.0811,  ...,  5011.4873,  4992.7109,\n",
      "                                                                                           4890.0830],\n",
      "                                                                                         [15301.5107, 15171.3252, 15041.8262,  ...,  4958.8579,  4937.0625,\n",
      "                                                                                           4829.7988]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  245.5807,   248.6852,   252.5532,  ...,  6337.1797,  6453.3540,\n",
       "          6728.5181],\n",
       "        [   21.9938,    25.3738,    29.5216,  ...,  6931.5171,  7050.3867,\n",
       "          7331.9058],\n",
       "        [  228.6542,   232.0342,   236.1821,  ...,  6371.8721,  6488.8457,\n",
       "          6764.6738],\n",
       "        ...,\n",
       "        [15080.5449, 14954.1230, 14828.4131,  ...,  5082.9565,  5067.2808,\n",
       "          4968.5518],\n",
       "        [15146.9541, 15018.6699, 14891.0811,  ...,  5011.4873,  4992.7109,\n",
       "          4890.0830],\n",
       "        [15301.5107, 15171.3252, 15041.8262,  ...,  4958.8579,  4937.0625,\n",
       "          4829.7988]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# (-0.5 * (mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1) / scale3d_squared).exp()\n",
    "ic(mean3d_tile_unsq1[:3])\n",
    "ic(gt_points_tile_unsq0[0, :3])\n",
    "ic((mean3d_tile_unsq1 - gt_points_tile_unsq0).shape)\n",
    "ic((mean3d_tile_unsq1 - gt_points_tile_unsq0)[:3,:3])\n",
    "ic((mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1)[:3,:3])\n",
    "ic(scale3d_squared)\n",
    "ic(((mean3d_tile_unsq1 - gt_points_tile_unsq0).pow(2).sum(-1) / scale3d_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02285684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(np.array([0.0758,  0.0996, -0.0848])**2)\n",
    "# np.array([0.3084, 0.4932, 0.4271])-np.array([0.2326, 0.3935, 0.5118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| key: 'rgb', data[key].shape: torch.Size([1, 256, 256, 3])\n",
      "ic| key: 'camera', data[key].shape: torch.Size([1, 34])\n",
      "ic| key: 'depth', data[key].shape: torch.Size([1, 256, 256])\n",
      "ic| key: 'alpha', data[key].shape: torch.Size([1, 256, 256])\n",
      "ic| key: 'depth_range', data[key].shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# use only one training image\n",
    "device = 'cuda'\n",
    "folder = './data/B075X65R3X'\n",
    "data = read_all(folder, resize_factor=0.5)\n",
    "data = {k: v.to(device) for k, v in data.items()}\n",
    "data['depth_range'] = torch.Tensor([[1,3]]*len(data['rgb'])).to(device)\n",
    "for key,value in data.items():\n",
    "    data[key] = value[0:1]\n",
    "    ic(key, data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones([3,6]).sum(axis=1)\n",
    "b = torch.ones([3])*3\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
