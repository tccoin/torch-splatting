{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import rkhs_splatting.utils as utils\n",
    "from rkhs_splatting.trainer import Trainer\n",
    "import rkhs_splatting.utils.loss_utils as loss_utils\n",
    "from rkhs_splatting.utils.data_utils import read_all\n",
    "from rkhs_splatting.utils.camera_utils import to_viewpoint_camera\n",
    "from rkhs_splatting.utils.point_utils import get_point_clouds, get_point_clouds_tiles\n",
    "from rkhs_splatting.gauss_model import RKHSModelGlobalScale\n",
    "from rkhs_splatting.gauss_render import RKHSRendererGlobalScale\n",
    "import datetime\n",
    "import pathlib\n",
    "from icecream import ic\n",
    "\n",
    "import contextlib\n",
    "\n",
    "from pytorch_memlab import LineProfiler\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "USE_GPU_PYTORCH = True\n",
    "USE_PROFILE = False\n",
    "\n",
    "class GSSTrainer(Trainer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = kwargs.get('data')\n",
    "        self.gaussRender = RKHSRendererGlobalScale(**kwargs.get('render_kwargs', {}))\n",
    "        self.lambda_dssim = 0.2\n",
    "        self.lambda_depth = 0.0\n",
    "        # create a file self.results_folder / f'eval.csv'\n",
    "        with open(self.results_folder / 'eval.csv', 'w') as f:\n",
    "            f.write('iter,loss,total,l1,ssim,depth,psnr\\n')\n",
    "        self.tensorboard_writer = SummaryWriter(log_dir=self.results_folder)\n",
    "\n",
    "\n",
    "    \n",
    "    def on_train_step(self):\n",
    "        ind = np.random.choice(len(self.data['camera']))\n",
    "        camera = self.data['camera'][ind]\n",
    "        rgb = self.data['rgb'][ind]\n",
    "        depth = self.data['depth'][ind]\n",
    "        alpha = self.data['alpha'][ind]\n",
    "        mask = (self.data['alpha'][ind] > 0.5)\n",
    "        if USE_GPU_PYTORCH:\n",
    "            camera = to_viewpoint_camera(camera)\n",
    "\n",
    "        if USE_PROFILE:\n",
    "            prof = profile(activities=[ProfilerActivity.CUDA], with_stack=True)\n",
    "        else:\n",
    "            prof = contextlib.nullcontext()\n",
    "\n",
    "        with prof:\n",
    "            max_scaling = torch.scalar_tensor(0.025, device=\"cuda\")\n",
    "            if self.model.get_scaling > max_scaling:\n",
    "                self.model.set_scaling(max_scaling)\n",
    "            out = self.gaussRender(pc=self.model, camera=camera)\n",
    "\n",
    "        if USE_PROFILE:\n",
    "            print(prof.key_averages(group_by_stack_n=True).table(sort_by='self_cuda_time_total', row_limit=20))\n",
    "\n",
    "\n",
    "\n",
    "        l1_loss = loss_utils.l1_loss(out['render'], rgb)\n",
    "        depth_loss = loss_utils.l1_loss(out['depth'][..., 0][mask], depth[mask])\n",
    "        ssim_loss = 1.0-loss_utils.ssim(out['render'], rgb)\n",
    "\n",
    "        # ic(self.data['camera'][ind].unsqueeze(0).shape)\n",
    "        # ic(depth.shape)\n",
    "        # ic(alpha.shape)\n",
    "        # ic(rgb.shape)\n",
    "\n",
    "        points = get_point_clouds_tiles(self.data['camera'][ind].unsqueeze(0), depth.unsqueeze(0), alpha.unsqueeze(0), rgb.unsqueeze(0))\n",
    "\n",
    "\n",
    "        rkhs_loss = loss_utils.rkhs_global_scale_loss(out['tiles'], points, rgb, self.model.get_scaling)\n",
    "\n",
    "\n",
    "        # total_loss = (1-self.lambda_dssim) * l1_loss + self.lambda_dssim * ssim_loss + depth_loss * self.lambda_depth\n",
    "        total_loss = rkhs_loss[0] + rkhs_loss[1] - 2*rkhs_loss[2]\n",
    "        psnr = utils.img2psnr(out['render'], rgb)\n",
    "        log_dict = {'total': total_loss,'l1':l1_loss, 'ssim': ssim_loss, 'depth': depth_loss, 'psnr': psnr}\n",
    "\n",
    "        with open(self.results_folder / 'eval.csv', 'a') as f:\n",
    "            f.write(f'{self.step},{total_loss},{l1_loss},{ssim_loss},{depth_loss},{psnr}\\n')\n",
    "\n",
    "        self.tensorboard_writer.add_scalar('loss/total', total_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss0', rkhs_loss[0], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss1', rkhs_loss[1], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/rkhs_loss2', rkhs_loss[2], self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/l1', l1_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/ssim', ssim_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('loss/depth', depth_loss, self.step)\n",
    "        self.tensorboard_writer.add_scalar('params/scaling', self.model.get_scaling, self.step)\n",
    "        \n",
    "        self.tensorboard_writer.add_scalar('psnr', psnr, self.step)\n",
    "\n",
    "        return total_loss, log_dict\n",
    "\n",
    "    def on_evaluate_step(self, **kwargs):\n",
    "        import matplotlib.pyplot as plt\n",
    "        ind = np.random.choice(len(self.data['camera']))\n",
    "        camera = self.data['camera'][ind]\n",
    "        if USE_GPU_PYTORCH:\n",
    "            camera = to_viewpoint_camera(camera)\n",
    "\n",
    "        rgb = self.data['rgb'][ind].detach().cpu().numpy()\n",
    "        out = self.gaussRender(pc=self.model, camera=camera)\n",
    "        rgb_pd = out['render'].detach().cpu().numpy()\n",
    "        depth_pd = out['depth'].detach().cpu().numpy()[..., 0]\n",
    "        depth = self.data['depth'][ind].detach().cpu().numpy()\n",
    "        depth = np.concatenate([depth, depth_pd], axis=1)\n",
    "        depth = (1 - depth / depth.max())\n",
    "        depth = plt.get_cmap('jet')(depth)[..., :3]\n",
    "        image = np.concatenate([rgb, rgb_pd], axis=1)\n",
    "        image = np.concatenate([image, depth], axis=0)\n",
    "        utils.imwrite(str(self.results_folder / f'image-{self.step}.png'), image)\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "folder = './data/B075X65R3X'\n",
    "data = read_all(folder, resize_factor=0.5)\n",
    "data = {k: v.to(device) for k, v in data.items()}\n",
    "data['depth_range'] = torch.Tensor([[1,3]]*len(data['rgb'])).to(device)\n",
    "\n",
    "# ic(data['camera'].shape)\n",
    "# ic(data['depth'].shape)\n",
    "# ic(data['alpha'].shape)\n",
    "# ic(data['rgb'].shape)\n",
    "\n",
    "\n",
    "points = get_point_clouds(data['camera'], data['depth'], data['alpha'], data['rgb'])\n",
    "raw_points = points.random_sample(2**14)\n",
    "# raw_points.write_ply(open('points.ply', 'wb'))\n",
    "\n",
    "gaussModel = RKHSModelGlobalScale(sh_degree=4, debug=False)\n",
    "gaussModel.create_from_pcd(pcd=raw_points)\n",
    "\n",
    "render_kwargs = {\n",
    "    'white_bkgd': True,\n",
    "}\n",
    "# folder_name = datetime.datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "folder_name = 'test'\n",
    "results_folder = pathlib.Path('result/'+folder_name)\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trainer = GSSTrainer(model=gaussModel, \n",
    "    data=data,\n",
    "    train_batch_size=1, \n",
    "    train_num_steps=25000,\n",
    "    i_image =100,\n",
    "    train_lr=1e-3, \n",
    "    amp=False,\n",
    "    fp16=False,\n",
    "    results_folder=results_folder,\n",
    "    render_kwargs=render_kwargs,\n",
    ")\n",
    "\n",
    "trainer.on_evaluate_step()\n",
    "trainer.on_train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  gaussian_splatting.utils.camera_utils import parse_camera\n",
    "from icecream import ic\n",
    "from plotly_utils import *\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for ind in range(10):\n",
    "    camera = trainer.data['camera'][ind].unsqueeze(0)\n",
    "    rgb = trainer.data['rgb'][ind].unsqueeze(0)\n",
    "    depth = trainer.data['depth'][ind].unsqueeze(0)\n",
    "    alpha = trainer.data['alpha'][ind].unsqueeze(0)\n",
    "    mask = (trainer.data['alpha'][ind] > 0.5).unsqueeze(0)\n",
    "    Hs, Ws, intrinsics, c2ws = parse_camera(camera)\n",
    "    W, H = int(Ws[0].item()), int(Hs[0].item())\n",
    "\n",
    "\n",
    "    points = get_point_clouds_tiles(camera, depth, alpha, rgb)\n",
    "    N = len(points)\n",
    "    M = len(points[0])\n",
    "    P = points[0][0].coords.shape[0]\n",
    "\n",
    "    # plot rgb with plotly\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.io as pio\n",
    "    import plotly.express as px\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "    # image = (rgb[0].detach().cpu().numpy()*255).astype(np.uint8)\n",
    "    # fig = go.Figure(data=[go.Image(z=image)])\n",
    "    # fig.show()\n",
    "\n",
    "    # depth_image = depth[0].detach().cpu().numpy()\n",
    "    # fig_depth = px.imshow(depth_image, color_continuous_scale='gray')\n",
    "    # fig_depth.update_traces(hoverinfo=\"x+y+z\", name=\"\")\n",
    "    # fig_depth.show()\n",
    "\n",
    "    transform = c2ws[0].detach().cpu().numpy()\n",
    "    plot_camera(fig, transform[:3, :3], transform[:3, 3], 3, 'camera', True)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            plot_points(fig, points[i][j].coords, f'points{i*N+j}', points[i][j].select_channels(['R', 'G', 'B']))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
